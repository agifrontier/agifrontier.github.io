---
layout: default
title: "HaluMem: Evaluating Hallucinations in Memory Systems of Agents"
---

# AI Agent记忆也“幻觉”？HaluMem：首个记忆系统“CT扫描”基准，精准定位错误根源

当你的AI助手前一秒还记得你喜欢喝拿铁，下一秒却又问你是否偏爱美式咖啡时，你可能会觉得它有点“健忘”。这种现象在AI领域被称为“幻觉”，而当它发生在AI的记忆系统中时，问题就变得尤为棘手。

> **论文标题**：HaluMem: Evaluating Hallucinations in Memory Systems of Agents
> **ArXiv URL**：http://arxiv.org/abs/2511.03506v2

AI Agent要实现真正的长期交互和个性化，一个可靠的记忆系统是不可或缺的。然而，在记忆的存入、更新和提取过程中，AI常常会凭空捏造、记错、遗忘甚至自相矛盾。

以往的评测方法大多是“黑盒测试”，只看最终的问答结果，就像医生只问病人“还好吗”，却不做任何检查。我们知道AI答错了，但不知道问题出在哪个环节：是信息提取错了，还是更新记忆时出了岔子？

为了解决这个难题，来自中国电信研究院、哈尔滨工程大学等机构的研究者们推出了**HaluMem**，这是首个专为AI Agent记忆系统设计的**操作级**（operation-level）幻觉评测基准。它就像一台“CT扫描仪”，能逐层扫描记忆系统的核心操作，精准定位幻觉的病灶。

### 为何需要“手术刀”？现有评测的局限

传统的记忆评测范式通常是端到端的。它们向系统抛出一个问题，然后评估最终答案的质量。这种方式虽然简单，但无法揭示问题的根源。

<img src="/images/2511.03506v2/x2.jpg" alt="HaluMem与现有评测方法的对比" style="width:90%; max-width:700px; margin:auto; display:block;">
*图注：HaluMem（右）能深入记忆操作的各个环节进行评测，而传统方法（左）只能进行端到端的黑盒评估。*

一个错误的答案，其背后可能的原因多种多样：
*   **提取幻觉**：从对话中提取了不存在或错误的信息。
*   **更新幻觉**：在更新旧记忆时，发生了错误、遗漏或冲突。
*   **检索幻觉**：检索到了不相关的记忆，导致回答牛头不对马嘴。

如果不能定位问题，我们就无法系统性地修复它。HaluMem的出现，正是为了提供一把“手术刀”，解剖记忆系统的内部运作，实现从“看症状”到“找病因”的转变。

### HaluMem：AI记忆系统的“CT扫描仪”

HaluMem的核心思想是将复杂的记忆过程拆解为三个关键的操作任务，并对每个任务进行独立评估：

1.  **记忆提取**（**Memory Extraction**）：评测系统能否从海量对话中准确识别并抽取出关键信息点（如用户的偏好、重要事件），同时过滤掉无关或虚假的干扰信息。

2.  **记忆更新**（**Memory Updating**）：当新的对话内容与已有记忆相关时，评测系统能否正确地修改、合并或替换旧记忆，以保证信息的一致性和时效性。

3.  **记忆问答**（**Memory Question Answering**）：在经过前两个环节后，最终检验系统利用其记忆库回答问题的端到端能力。

为了支撑这套评测框架，研究团队构建了两个大规模、以用户为中心的多轮对话数据集：**HaluMem-Medium**和**HaluMem-Long**。这两个数据集包含约1.5万个记忆点和3500个问题，其中HaluMem-Long的平均对话上下文长度更是超过了惊人的100万Token，用以测试系统在超长文本环境下的鲁棒性。

<img src="/images/2511.03506v2/x3.jpg" alt="HaluMem的构建流程" style="width:90%; max-width:700px; margin:auto; display:block;">
*图注：HaluMem数据集的构建流程，通过多阶段的扩展和标注，确保了数据的质量和复杂性。*

### 实验发现：幻觉会“滚雪球”

研究团队使用HaluMem对多个顶尖的记忆系统（如Mem0, Memobase, Supermemory, Zep）进行了全面“体检”。结果发人深省：

**1. 幻觉会累积和放大**
实验明确揭示了幻觉的“滚雪球”效应。在记忆提取和更新阶段产生的小错误，会不断累积，并在最终的问答环节被放大，导致更严重的错误。这证明了上游操作的准确性至关重要。

**2. 现有系统仍有巨大提升空间**
在最终的问答任务中，即便是表现最好的系统，其准确率也未能超过56%。同时，幻觉率和遗忘率居高不下，尤其是在HaluMem-Long的长上下文场景下，性能普遍出现下滑。

<img src="/images/2511.03506v2/x5.jpg" alt="不同记忆系统在各类问题上的表现" style="width:85%; max-width:600px; margin:auto; display:block;">
*图注：不同记忆系统在六种不同类型问题上的表现。可以看出，在多跳推理、动态更新等复杂问题上，所有系统的表现都显著下降。*

**3. 对不同类型信息的处理能力不均**
研究发现，所有系统在捕捉静态的**个人画像**（Persona）类记忆时表现稍好，但在理解动态的**事件**（Event）和**关系**（Relationship）变化时则显得力不从心。这表明当前记忆系统对复杂语义和动态变化的建模能力仍有欠缺。

**4. 写入操作是效率瓶颈**
效率分析显示，记忆的写入（提取和更新）阶段耗时远超检索阶段，是主要的性能瓶颈。要提升AI Agent的交互流畅度，优化写入效率是关键。

### 结论

HaluMem的提出，为AI记忆系统的幻觉问题提供了一个前所未有的诊断工具。它不再满足于对最终结果的模糊评估，而是深入到记忆操作的“细胞层面”，精准定位问题所在。

实验结果清晰地表明，当前AI记忆系统远未成熟，幻觉的产生是一个系统性问题，根源于记忆提取和更新等基础操作的不可靠。

这项研究不仅为我们揭示了问题的严重性，更指明了未来的方向：开发更具可解释性、可约束的记忆操作机制，从源头上抑制幻觉的产生和传播，才能最终打造出我们真正信赖的、具备可靠长期记忆的AI Agent。