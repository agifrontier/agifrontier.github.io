---
layout: default
title: "BEAM: Brainwave Empathy Assessment Model for Early Childhood"
---

# BEAM: Brainwave Empathy Assessment Model for Early Childhood

- **ArXiv URL**: http://arxiv.org/abs/2509.06620v1

- **作者**: Ruoxi Wu; Kaidong Wang; Gaofeng Wu; Han Zhang; Zihao Zhu; Yan Liang; Chen Xie

- **发布机构**: East China Normal University; Fudan University; Shanghai Clinical Research and Trial Center; ShanghaiTech University; Xiamen Children’s Hospital

---

# TL;DR
本文提出了一种名为 BEAM 的深度学习框架，它通过分析幼儿观看视频时的多视角脑电图（EEG）信号，结合特征融合与对比学习技术，实现了对儿童共情水平（表现为助人意愿）的客观、准确预测。

# 关键定义
本文主要沿用了认知神经科学中的现有概念，并基于此构建模型。以下是对理解本文至关重要的核心术语：

*   **认知共情 (Cognitive Empathy)**：在本文中特指**心智理论 (Theory of Mind, ToM)**，即理解和采纳他人视角的能力。这是共情的认知成分。
*   **情感共情 (Emotional Empathy, EM)**：指在情感上分享他人情绪状态（包括效价和强度）的能力。这是共情的感性成分。
*   **BEAM (脑波共情评估模型, Brainwave Empathy Assessment Model)**：本文提出的深度学习框架名称。该模型旨在通过处理 ToM 和 EM 事件相关的多视角 EEG 信号，来评估和预测幼儿的共情水平。

# 相关工作
目前，对幼儿共情水平的评估面临着严峻的挑战。主流方法，如自我报告、家长问卷或行为观察标注，严重依赖主观判断，不仅容易产生偏见，也无法实时、客观地捕捉共情形成的过程。

尽管脑电图（EEG）技术为客观测量提供了可能，但现有研究存在明显瓶颈：
1.  **研究对象局限**：大多数基于 EEG 的共情研究集中于成年人，缺乏针对幼儿的模型。
2.  **特征提取粗糙**：已有方法主要提取静态的、总结性的脑电特征（如脑区不对称性），忽略了共情过程中关键的动态时间信息和复杂的空间模式。
3.  **维度单一化**：研究常将共情视为单一结构，未能全面地对其认知（ToM）和情感（EM）两大核心组成部分进行综合建模。

因此，本文旨在解决上述问题，提出一个能够客观、高效地利用 EEG 信号评估幼儿共情水平的深度学习框架。该框架专门处理共情的双重维度，并从未经处理的脑电信号中学习时空动态特征。

# 本文方法
本文提出了脑波共情评估模型（BEAM），一个利用多视角脑电信号预测幼儿共情水平的深度学习框架。其核心思想是分别从引发认知共情（ToM）和情感共情（EM）的事件中提取脑电特征，然后通过一个精巧的融合机制将二者结合，最终通过对比学习增强模型的判别能力。

<img src="/images/2509.06620v1/model_DPI1000.jpg" alt="BEAM 整体架构" style="width:90%; max-width:700px; margin:auto; display:block;">

### 输入与预处理
*   **数据来源**：模型使用来自中华宝宝队列研究项目（CBCP）的数据，包含57名4至6岁儿童观看动画短片《暴力云与送子鹳》时的32通道EEG记录。
*   **标签定义**：共情水平通过观影后测试中的“助人意愿”得分来衡量，并使用中位数分割法将儿童分为高、低共情两组。
*   **数据分割**：根据先前研究，视频被切分为6个ToM事件片段和8个EM事件片段。EEG信号以4秒为窗长、1秒为步长进行切片，形成多个样本（ToM 65个，EM 43个）。
*   **数据增强**：为缓解类别不平衡问题，采用短时傅里叶变换（STFT）将EEG信号转至频域，添加高斯噪声后，再通过逆变换（iSTFT）重建信号。

### 网络架构
BEAM框架主要由编码器、特征融合模块和对比学习模块三部分构成。

#### 编码器
*   **模型选择**：采用 **LaBraM (Large Brain Model)** 作为特征提取器。LaBraM 是一个基于 Transformer 的大规模预训练EEG模型，能够有效捕捉脑电信号的通用时空表征。
*   **功能**：对于输入的ToM和EM脑电片段，LaBraM编码器独立工作，分别提取出代表认知和情感维度的特征向量 $Z\_{\text{ToM}}$ 和 $Z\_{\text{EM}}$。其优势在于能同时整合信号的全局和局部信息。

#### 特征融合
*   **创新点**：为了有效整合ToM和EM这两种互补信息，本文设计了一种新颖的特征融合策略，而非简单的拼接。该策略将每个视角的特征 $Z\_{n}$ 分解为**共享部分** $\mathrm{Com}(Z\_{n})$ 和**独有部分** $\mathrm{Sep}(Z\_{n})$。
*   **优化目标**：通过一个专门的融合损失函数 $\mathcal{L}\_{\mathrm{Fusion}}$ 来实现两个目标：1) 使不同视角（ToM和EM）的共享特征尽可能相似；2) 使独有特征尽可能不同。
    

    {% raw %}$$
    \mathcal{L}_{\mathrm{Fusion}}=\frac{\left \mid \mathrm{Sim}_{\mathrm{Sep}}\right \mid }{\mathrm{Sim}_{\mathrm{Com}}+1+\epsilon}
    $${% endraw %}


    其中，$\mathrm{Sim}\_{\mathrm{Com}}$ 和 $\mathrm{Sim}\_{\mathrm{Sep}}$ 分别是共享部分和独有部分的余弦相似度。
*   **融合结果**：最终的融合特征由三部分拼接而成：ToM的独有部分、两个视角的平均共享部分、以及EM的独有部分。
    

    {% raw %}$$
    \mathbf{Z}_{ToM,EM}=\left(\mathrm{Sep}(\mathbf{Z}_{\text{ToM}}),\mathrm{Common},\mathrm{Sep}(\mathbf{Z}_{\text{EM}})\right)
    $${% endraw %}


    其中 $\mathrm{Common}=0.5\left(\mathrm{Com}(\mathbf{Z}\_{\text{ToM}})+\mathrm{Com}(\mathbf{Z}\_{\text{EM}})\right)$。

#### 对比学习
*   **目的**：为了增强模型的判别能力，减少受试者间的个体差异对分类结果的干扰。
*   **方法**：在特征融合后，引入了基于 **InfoNCE** 的对比学习损失函数 $\mathcal{L}\_{\text{Contra}}$。
    

    {% raw %}$$
    \mathcal{L}_{\text{Contra}}=-\frac{1}{B}\sum_{i=1}^{B}\log\left(\frac{\exp\left(\frac{\mathbf{z}_{i}\cdot\mathbf{z}_{i+}}{\tau}\right)}{\sum_{j=1}^{B}\exp\left(\frac{\mathbf{z}_{i}\cdot\mathbf{z}_{j}}{\tau}\right)}\right)
    $${% endraw %}


    该损失函数通过拉近同类样本（正样本 $z\_{i+}$）的特征表示，同时推远不同类样本（负样本）的特征表示，从而使得特征空间中的类间距离最大化，类内距离最小化。$\tau$ 是控制分布锐度的温度超参数。

# 实验结论

### 与SOTA模型对比
本文将BEAM模型与多种先进的EEG分类方法进行了比较。结果表明，BEAM在准确率、特异性和敏感性等所有关键指标上均显著优于其他模型，证明了其卓越的性能。同时，BEAM结果的标准差更小，表明其模型具有更高的稳定性和可靠性。

<br>


| 方法 | 准确率 $\uparrow$ | 特异性 $\uparrow$ | 敏感性 $\uparrow$ |
| :--- | :--- | :--- | :--- |
| ST-Transformer [4] | 0.512$\pm$0.021 | 0.511$\pm$0.022 | 0.512$\pm$0.022 |
| SVM-asymmetry [8] | 0.538$\pm$0.001 | 0.533$\pm$0.002 | 0.536$\pm$0.002 |
| BIOT [14] | 0.564$\pm$0.012 | 0.571$\pm$0.018 | 0.560$\pm$0.016 |
| **本文方法** | **0.647$\pm$0.008** | **0.651$\pm$0.009** | **0.646$\pm$0.009** |

<br>

### 消融实验
为了验证模型各组件的有效性，本文进行了两组消融实验。

#### 共情成分的有效性
实验结果显示，单独使用ToM（认知共情）特征的预测准确率（0.614）高于单独使用EM（情感共情）特征（0.588），表明在本任务中，ToM提供了更强的预测信号。然而，将ToM和EM特征进行融合后，性能得到了显著提升，最终准确率达到0.647，证明了多视角信息融合的必要性和有效性。

<br>


| 方法 (使用对比学习) | 准确率$\uparrow$ | 特异性$\uparrow$ | 敏感性$\uparrow$ |
| :--- | :--- | :--- | :--- |
| EM (×) | 0.588$\pm$0.002 | 0.592$\pm$0.002 | 0.577$\pm$0.002 |
| EM (✓) | 0.592$\pm$0.003 | 0.588$\pm$0.002 | 0.593$\pm$0.003 |
| ToM (×) | 0.614$\pm$0.007 | 0.621$\pm$0.010 | 0.611$\pm$0.009 |
| ToM (✓) | 0.616$\pm$0.008 | 0.619$\pm$0.011 | 0.622$\pm$0.009 |
| ToM+EM (×) | 0.621$\pm$0.014 | 0.623$\pm$0.011 | 0.620$\pm$0.010 |
| **ToM+EM (✓)** | **0.641$\pm$0.012** | **0.639$\pm$0.016** | **0.642$\pm$0.012** |

<br>

*(注：上表中的ToM+EM (✓) 对应下表中的 Fusion(×) Contrast(✓) 行)*

#### 网络模块的有效性
对网络模块的消融研究表明，**对比学习模块的贡献最大**。仅引入对比学习就能将准确率从0.621提升至0.641，这说明它在增强特征判别力和减少个体差异方面起到了关键作用。而特征融合模块在对比学习的基础上进一步带来了性能提升和稳定性增强，最终使模型达到最佳性能。

<br>


| 融合模块 | 对比学习 | 准确率$\uparrow$ | 特异性$\uparrow$ | 敏感性$\uparrow$ |
| :--- | :--- | :--- | :--- | :--- |
| × | × | 0.621$\pm$0.014 | 0.623$\pm$0.011 | 0.620$\pm$0.010 |
| ✓ | × | 0.620$\pm$0.007 | 0.621$\pm$0.007 | 0.622$\pm$0.009 |
| × | ✓ | 0.641$\pm$0.012 | 0.639$\pm$0.016 | 0.642$\pm$0.012 |
| **✓** | **✓** | **0.647$\pm$0.008** | **0.651$\pm$0.009** | **0.646$\pm$0.009** |

<br>

### 总结
本文提出的BEAM模型成功地将深度学习应用于幼儿共情评估，其创新性地结合了多视角EEG特征提取、特征融合和对比学习，在客观性和准确性上均超越了现有方法。尽管存在数据集规模有限和标签定义简化等局限性，但该研究为儿童共情发展的客观量化和早期干预提供了极具潜力的科学工具和新思路。未来的工作将致力于扩充数据集、优化标签体系和开发更适合儿童的脑电编码器。