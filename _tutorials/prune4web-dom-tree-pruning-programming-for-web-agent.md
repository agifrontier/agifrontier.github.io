---
layout: default
title: "Prune4Web: DOM Tree Pruning Programming for Web Agent"
---

# LLM不读万行代码：Prune4Web让网页元素定位精度飙升至88%！

<img src="/images/2511.21398v1/A__title.jpg" alt="" style="width:90%; max-width:700px; margin:auto; display:block;">

当AI Agent试图帮我们在复杂的网页上预订机票或在线购物时，它们常常会“迷失”在由成千上万行代码组成的文档对象模型（DOM）中。这就像让一个人在一部万页电话簿里找一个没有具体地址的名字，效率低下且错误频出。传统的解决方法要么是粗暴地截断信息，要么是依赖低效的启发式方法。

> ArXiv URL：http://arxiv.org/abs/2511.21398v1

有没有一种更聪明的方式？来自北航的研究者给出了答案：**Prune4Web**。它提出了一种颠覆性的范式——不再强迫大模型（LLM）去“阅读”整个庞杂的DOM，而是让LLM“编写”一个轻量级的Python程序，来精准地“捕捞”出我们需要的网页元素。这一转变，直接将候选元素数量减少了25到50倍，并将底层定位精度从46.8%戏剧性地提升到了88.28%！

![Prune4Web vs. Existing Agents](images/page_0_Figure_9.jpg)

*▲ Prune4Web与现有Web Agent的范式对比*

### Prune4Web：规划、编程、定位的三步走框架

Prune4Web将复杂的网页自动化任务拆解为一个清晰的三阶段工作流，每一步都由专门的模块高效处理。

1.  **任务规划（Planning）**：首先，一个“规划师”（Planner）模型接收高级任务指令（如“预订一张去纽约的机票”）和网页截图，将其分解为具体、可执行的低级子任务（如“找到目的地输入框并输入NYC”）。

2.  **编程过滤（Programmatic Filtering）**：这是Prune4Web的核心创新。基于规划师输出的子任务，一个“编程过滤器”（Programmatic Element Filter）并不会去读取整个DOM，而是让LLM生成一个简短的Python评分脚本。

3.  **动作执行（Action Grounding）**：最后，“执行者”（Action Grounder）接收到经过程序筛选后的、数量极少的候选元素列表，并从中精确选择目标元素，生成最终的执行动作（如点击、输入等）。

这个流程的精妙之处在于，它将LLM从繁重的、低效的“阅读理解”任务中解放出来，让其专注于更高层次的“编程”和“决策”。

![Prune4Web Workflow](images/page_3_Figure_0.jpg)

*▲ Prune4Web的完整工作流*

### 核心魔法：DOM树剪枝编程

Prune4Web的真正魔法在于其**DOM树剪枝编程**（**DOM Tree Pruning Programming, DTPP**）机制。

传统的Web Agent是怎么做的？它们将整个HTML或DOM（通常包含1万到10万个Token）输入给LLM，让LLM在庞大的上下文中寻找目标元素。这不仅会超出许多模型的上下文窗口限制，还会导致“注意力稀释”，即模型在海量无关信息中迷失方向。

Prune4Web另辟蹊径。它发现，规划师生成的低级子任务（如“找到目的地输入框”）本身就包含了丰富的语义线索。于是，它不让LLM直接处理DOM，而是提示LLM根据这些线索生成一个Python评分函数。

这个函数非常轻量，它会遍历整个DOM树，根据关键词、元素属性等为每个元素打分。例如，对于“找到目的地输入框”，生成的程序可能会给包含“destination”、“dest”等关键词、且标签为$$<input>$$的元素赋予高分。

这种“移交”策略有两大优势：

*   **效率**：执行一个小型Python脚本远比LLM处理数万Token的文本要快得多、成本低得多。

*   **精度**：通过编程方式进行结构化搜索，避免了LLM在长文本中可能出现的幻觉或忽略关键信息的风险。

最终，只有得分最高的少数几个元素会被提交给下游的“执行者”，大大降低了最终决策的难度。

### 如何训练一个“编程大师”？

要让LLM学会这种“编程”技巧，高质量的训练数据和巧妙的训练策略缺一不可。

该研究首先构建了一个自动化的数据标注流程，在现有的Mind2Web数据集基础上，利用GPT-4o为每一步交互生成了中间标签，包括低级子任务、用于生成评分程序的关键词和权重等。

在训练方面，Prune4Web采用了一种创新的**两轮对话训练策略**（**two-turn dialogue training strategy**），将规划师、过滤器和执行者统一到一个模型中进行联合优化。

1.  **监督微调（SFT）**：首先，使用标注好的数据对模型进行监督微调，让模型初步学会从任务到子任务、再到评分程序和最终动作的完整流程。

2.  **强化微调（RFT）**：接着，为了提升规划师的长期规划能力，研究采用了强化学习进行微调。这里的奖励机制设计得非常巧妙：它引入了**分层奖励**（**Hierarchical Reward Mechanism**）。如果编程过滤器生成的程序成功地将正确答案保留在了候选列表中，那么上游的规划师就会获得一个正向的“中间奖励”。这种及时的反馈，能有效指导规划师学习如何分解出更有利于后续步骤的任务。

 
*▲ 表格节选：训练策略消融实验，SFT+RFT结合两轮对话的统一模型效果最佳*

### 惊人的实验效果

Prune4Web的性能表现令人印象深刻。

在专门为验证其核心能力而构建的低级子任务定位基准上，Prune4Web将**元素定位的准确率从基线的46.8%一举提升至88.28%**，证明了编程过滤范式的巨大优势。

更有趣的是，实验发现，即使是小模型，也能通过这种方式学会高效过滤。

![Recall@N Performance](images/page_6_Figure_11.jpg)

*▲ 不同模型在编程过滤阶段的Recall@N表现*

上图显示了不同规模的模型在过滤后，正确答案被包含在前N个候选中的概率（Recall@N）。可以看到，即使是0.5B的微调模型，其表现也与3B模型几乎持平，并且远超强大的GPT-4o。这说明，**DOM树剪枝编程**成功地将一个复杂的推理问题，转化成了一个小模型也能轻松掌握的、简单的程序生成问题。

### 总结

Prune4Web为Web Agent领域中的信息过载问题提供了一个优雅且高效的解决方案。它通过“让LLM写程序来代替阅读”的核心思想，巧妙地绕过了当前大模型在处理超长上下文时的瓶颈，实现了效率和精度的双重飞跃。这种从“处理”到“编程”的范式转变，不仅为开发更强大、更可靠的Web Agent铺平了道路，也为其他需要处理海量结构化信息的AI任务提供了宝贵的启示。