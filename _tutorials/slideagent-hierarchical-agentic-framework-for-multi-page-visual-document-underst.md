---
layout: default
title: "SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding"
---

# SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding

- **ArXiv URL**: http://arxiv.org/abs/2510.26615v1

- **作者**: Yiqiao Jin; Sumitra Ganesh; Rachneet Kaur; Srijan Kumar; Zhen Zeng

- **发布机构**: Georgia Institute of Technology; J.P. Morgan

---

# TL;DR
本文提出了SlideAgent，一个分层的智能体框架，通过将复杂多页视觉文档的理解任务分解为全局、页面和元素三个专业层级，并构建与查询无关的结构化知识库，显著提升了模型对幻灯片等文档的细粒度推理和综合理解能力。

# 关键定义
本文提出或主要依赖以下核心概念：

1.  **SlideAgent**: 一个多功能的智能体框架 (agentic framework)，专为理解多模态、多页面、多布局的视觉文档（尤其是幻灯片）而设计。
2.  **分层智能体架构 (Hierarchical Agentic Architecture)**: SlideAgent的核心设计，包含三个层级的专业智能体：
    *   **全局智能体 (Global Agent)**: 负责理解整个文档的主题、目标和叙事流，生成文档级别的知识。
    *   **页面智能体 (Page Agent)**: 负责分析单个页面的具体内容，并理解页面之间的关联，生成页面级别的知识。
    *   **元素智能体 (Element Agent)**: 负责解析页面内更细粒度的组成部分，如表格、图表、文本块，并理解其空间关系和功能，生成元素级别的知识。
3.  **知识构建阶段 (Knowledge Construction Stage)**: SlideAgent的第一个操作阶段。在此阶段，框架以自上而下的方式处理文档，生成一个与具体查询无关 (query-agnostic) 的分层知识库 $$K$$，包含全局、页面和元素三个层级的知识。
4.  **推理阶段 (Inference Stage)**: SlideAgent的第二个操作阶段。针对用户的具体查询 (query)，框架首先对查询进行分类，然后检索与查询相关 (query-specific) 的知识，并选择性地激活相应的智能体进行多层次推理，最终综合各智能体的输出，生成连贯的答案。

# 相关工作
当前，多模D大语言模型 (Multimodal Large Language Models, MLLMs) 在文档理解领域取得了显著进展。然而，在处理复杂的、多页面的视觉文档时，现有模型仍面临三大瓶颈：

1.  **整体性处理与细粒度缺失**: SOTA模型一次能处理的图像数量有限，且倾向于将每一页视为一个整体，从而忽略了回答用户查询时所必需的、元素级别的精细线索（如单个图表或文本框）。
2.  **领域专业性不足**: 多数MLLMs在自然图像上预训练，缺乏对金融图表、科学绘图等专业文档中特殊视觉语言（如颜色编码、图标含义、布局重要性）的理解能力。
3.  **空间推理能力弱**: 现有模型在空间推理方面表现不佳，难以准确定位视觉元素。此外，低分辨率的视觉编码器也常常会遗漏脚注、上标等文本细节。

本文旨在解决上述问题，特别是提升模型对多模态、多页面的复杂视觉文档（如幻灯片、报告）进行准确、细粒度推理的能力。

# 本文方法
SlideAgent框架通过一个分层的智能体系统来解决复杂视觉文档的理解问题。其核心思想是模仿人类处理信息的方式，将宏观理解与微观分析相结合。

<img src="/images/2510.26615v1/x2.jpg" alt="SlideAgent框架概览" style="width:85%; max-width:600px; margin:auto; display:block;">

如上图所示，SlideAgent的运作分为两个主要阶段：知识构建和推理。

## 知识构建阶段
此阶段的目标是为输入的多页文档 $\mathcal{P}=\{p\_{1},\ldots,p\_{ \mid \mathcal{P} \mid }\}$ 构建一个层次化的、与查询无关的知识库 $\mathcal{K}=\{\mathcal{K}\_{g},\mathcal{K}\_{p},\mathcal{K}\_{e}\}$。该过程以自上而下的方式利用三个专业智能体完成。

### 全局智能体
全局智能体 $\mathcal{M}\_{g}$ 负责生成文档级别的知识 $\mathcal{K}\_{g}$。它通过分析文档的开头几页（例如前三页）来捕捉整个文档的总体摘要、目标和叙事流，为高层级的推理建立主题背景。

### 页面智能体
对于文档中的每一页 $p\_{i}$，页面智能体 $\mathcal{M}\_{p}$ 顺序地生成页面级知识 $\mathcal{K}\_{p}^{i}$。该过程不仅依赖当前页面的视觉内容 $v\_{i}$，还融入了全局知识 $\mathcal{K}\_{g}$ 和前一页的知识 $\mathcal{K}\_{p}^{i-1}$。其形式化表示为：


{% raw %}$$
\mathcal{K}_{p}^{i}=\mathcal{M}_{p}(v_{i},\mathcal{K}_{g},\mathcal{K}_{p}^{i-1}),\quad i\in[1, \mid \mathcal{P} \mid ]
$${% endraw %}


其中 $\mathcal{K}\_{p}^{0}=\emptyset$。最终，所有页面的知识会汇总成 $\mathcal{K}\_{p} = \bigcup\_{i=1}^{ \mid \mathcal{P} \mid }\mathcal{K}\_{p}^{i}$，并被用来进一步优化全局知识 $\mathcal{K}\_{g}$。

### 元素智能体
为解决MLLM空间推理能力弱的问题，元素智能体 $\mathcal{M}\_{e}$ 专注于页面内部的细粒度元素。
首先，一个布局解析管道 (layout parsing pipeline) $f$ 会将每页 $p\_{i}$ 分解为一组元素，每个元素包含其页码 $i$、文本内容 $e\_{j}$、边界框坐标 $b\_{j}$ 和类型 $t\_{j}$。
接着，对于每个检测到的元素，元素智能体在其视觉内容和元数据的基础上，结合已有的全局和页面知识，生成元素级知识 $\mathcal{K}\_{e}^{j}$：


{% raw %}$$
\mathcal{K}_{e}^{j}=\mathcal{M}_{e}(i,v_{i},e_{j},b_{j},t_{j},\mathcal{K}_{g},\mathcal{K}_{p}^{i})
$${% endraw %}


$\mathcal{K}\_{e}^{j}$ 描述了元素的语义角色、功能目的及其与所在页面的关系，从而保留了精确的空间信息。

## 推理阶段
此阶段利用已构建的知识库 $\mathcal{K}$ 来回答用户查询 $q$。

### 查询分类
一个智能体编排器 (agent orchestrator) 首先将查询 $q$ 分类到预定义的类别中（如全局理解、事实查询、多跳推理、布局/视觉关系等）。不同类型的查询会激活不同的智能体组合，从而提高效率并减少噪音。例如，全局性问题只激活全局智能体，而细节性问题则需要页面和元素智能体。

### 子查询生成与检索
为了提高检索的准确性，原始查询 $q$ 会被用来生成多个针对关键实体的子查询 $\hat{Q}$。例如，对于查询“哪个国家的 GWP 最小”，系统会生成关于“国家”、“GWP”、“甜甜圈图”等关键词的子查询。然后，使用原始查询和子查询共同从知识库中检索最相关的页面和元素。

### 答案生成与综合
被激活的智能体分别生成中间答案和推理过程 $h\_{g}$ (全局), $h\_{p}$ (页面), $h\_{e}$ (元素)。
*   如果所有智能体的答案一致，或只有一个智能体被激活，则直接采纳其答案。
*   否则，一个答案综合器 (answer synthesizer) $\phi$ 会融合所有智能体的推理结果以及检索到的页面视觉信息，生成最终答案 $a$：


{% raw %}$$
a=\phi(h_{g},h_{p},h_{e},\{v_{i}:p_{i}\in\mathcal{R}(\hat{\mathcal{P}})\})
$${% endraw %}



## 创新点
*   **分层分解**: 本文最核心的创新是将复杂的文档理解任务分解为全局、页面、元素三个层次，并为每个层次分配专门的智能体，模拟了人类从宏观到微观的认知过程。
*   **查询无关的知识库**: 通过预先构建一个结构化的、与查询无关的知识库，将文档“理解”阶段与“问答”阶段分离，提高了推理时的效率和可扩展性。
*   **显式的元素级分析**: 通过集成的布局解析工具和元素智能体，直接解决了标准MLLM在空间定位和细粒度视觉细节理解上的短板。
*   **自适应的智能体调度**: 查询分类和智能体选择性激活机制，使得框架能够根据问题的不同需求，动态调整其推理策略，兼顾了效果和计算效率。

# 实验结论
实验在多个数据集（如SlideVQA, TechSlides, FinSlides）上进行，对比了SlideAgent与多种基线模型，包括独立的MLLMs（如GPT-4o, Gemini）和多模态RAG方法。

## 端到端性能


| 模型 | SlideVQA (Overall) | TechSlides (Overall) | FinSlides (Overall) |
| --- | --- | --- | --- |
| *多模态 RAG (Type 2) 与智能体方法 (Type 3)* | | | |
| COLPALI | 78.8 | 64.1 | 80.9 |
| VisRAG | 78.2 | 64.7 | 79.2 |
| VDocRAG | 80.0 | 67.0 | - |
| ViDoRAG | 81.1 | - | 82.2 |
| **SlideAgent (GPT-4o)** | **84.9** | **74.5** | **83.8** |
| *提升 vs GPT-4o* | *+7.9* | *+7.5* | *+5.5* |

<center>表1：SlideAgent与基于GPT-4o的SOTA方法的性能对比</center>

*   **跨模型架构的显著提升**: 如上表所示，无论基于专有模型（GPT-4o）还是开源模型（InternVL3-8B），SlideAgent都显著优于其基座模型和所有基线方法。例如，在SlideVQA数据集上，SlideAgent将GPT-4o的整体准确率提升了7.9个点，将InternVL3-8B提升了9.8个点。
*   **与顶尖MLLM的竞争力**: 尽管SlideAgent的基座模型GPT-4o在原始能力上可能略逊于Gemini 2.5等更强的模型，但通过其结构化的推理框架，SlideAgent能够弥补这一差距，甚至取得更优的性能。

<img src="/images/2510.26615v1/x4.jpg" alt="不同查询类型的性能" style="width:80%; max-width:300px; margin:auto; display:block;">

*   **在复杂查询上优势明显**: 根据查询类型分析（上图），SlideAgent在“多跳推理”（提升9.8个点）和“视觉/布局推理”（提升7.7个点）这两类复杂问题上取得了最大的性能增益。这证明了分层知识和元素级分析对于解决复杂推理链条至关重要。

## 知识构建的有效性


| 检索器 | MRR (基线) | MRR (w/ SA) | 提升 |
| --- | --- | --- | --- |
| *文本检索器* | | | |
| BM25 | 59.0 | 63.9 | +4.9 |
| SFR | 70.1 | 76.5 | +6.4 |
| *多模态检索器* | | | |
| COLPALI | 82.1 | 82.9 | +0.8 |
| VisRAG | 76.0 | 79.7 | +3.7 |

<center>表2：SlideAgent生成的知识对页面级检索性能的提升</center>

*   **提升检索性能**: 实验证明，SlideAgent在知识构建阶段生成的子查询 $\hat{Q}$ 和页面知识 $\mathcal{K}\_{p}$ 能够显著提升页面检索的准确性，特别是对于文本检索器（如SFR的MRR提升6.4点），这表明结构化知识为检索提供了更丰富的语义信号。

## 消融研究

<img src="/images/2510.26615v1/x3.jpg" alt="消融研究结果" style="width:85%; max-width:450px; margin:auto; display:block;">

*   **页面智能体的关键作用**: 消融实验表明，移除页面智能体（w/o P）导致的性能下降最为严重（GPT-4o下降6.3点）。这证实了页面智能体在连接全局上下文和元素细节、实现跨页面连贯推理方面扮演着不可或缺的角色。

## 总结
SlideAgent的分层智能体框架被证明是一种非常有效的方法。它通过将复杂的理解任务分解为多个协同工作的专业层级，成功克服了现有MLLMs在处理多页视觉文档时的局限性，尤其是在需要细粒度分析和多步推理的场景下，展现出巨大的优势。