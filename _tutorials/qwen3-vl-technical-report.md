---
layout: default
title: "Qwen3-VL Technical Report"
---

# Qwen3-VL重磅发布：256K上下文，三大架构升级打造全能多模态

<img src="/images/2511.21631v1/A__title.jpg" alt="" style="width:90%; max-width:700px; margin:auto; display:block;">

多模态大模型早已不是“看图说话”那么简单了。如今，它们必须能消化长篇图文报告，理解视频内容，甚至完成复杂的数理推理。

> ArXiv URL：http://arxiv.org/abs/2511.21631v1

就在最近，Qwen系列迎来了迄今最强的多模态模型——Qwen3-VL。它不仅在纯文本理解上超越了同类文本模型，更原生支持高达256K Token的图文视频混合输入，在长文档和视频理解上表现惊人。

更重要的是，它在MMMU、MathVista等高难度推理基准上取得了顶尖性能。这一切是如何实现的？这篇技术报告揭示了其背后的三大架构升级和全面的训练策略。

![Qwen3-VL 性能概览](images/page_0_Figure_8.jpg)

### 全新架构：三大核心升级

Qwen3-VL的强大能力，首先源于其架构上的三项关键创新。这些升级共同提升了模型对空间、时间和多层次信息的处理能力。

![Qwen3-VL 模型架构](images/page_2_Figure_0.jpg)

1.  **增强的交错式MRoPE**：为了更好地理解图像和视频，模型需要精确的位置信息。传统的位置编码方法可能导致频谱不平衡，影响长视频理解。Qwen3-VL采用了一种**增强的交错式多模态旋转位置编码**（**Enhanced interleaved-MRoPE**），将时间$t$、水平$h$和垂直$w$信息均匀地交错分布在嵌入维度中，显著改善了长距离时空建模能力。

2.  **DeepStack集成**：为了加强视觉与语言的对齐，该研究引入了DeepStack机制。它不再仅仅使用视觉编码器（ViT）最后一层的特征，而是从ViT的多个中间层提取视觉Token，并通过轻量级连接注入到大语言模型（LLM）的不同层级。这种多层次的特征融合，极大地丰富了模型的视觉表征，实现了更紧密的图文对齐。

3.  **基于文本的时间戳**：如何让模型精确感知视频中的时间？Qwen3-VL放弃了之前复杂的绝对时间编码，转而采用一种更直接的方式：为视频帧组添加明确的文本时间戳，例如$$<3.0 seconds>$$。这种方法虽然略微增加了上下文长度，但让模型能更简单、更精确地进行时间定位，对视频内容摘要和事件定位等任务至关重要。

### 全面革新的训练数据

高质量、大规模且多样化的数据是训练强大模型的基础。Qwen3-VL在数据构建上投入了巨大精力，覆盖了从基础感知到高级推理的方方面面。

-   **长文档与OCR**：通过合成多页PDF和生成跨页问答数据，模型学会了在数十页的文档中进行推理。同时，OCR数据扩展到39种语言，显著提升了多语言文字识别能力。

-   **空间理解与3D识别**：为了让模型理解物理世界，研究团队构建了专门的空间理解和3D接地数据集。这使得Qwen3-VL能够从单张图片中估计物体的3D空间位置。

-   **多模态代码**：通过整合UI截图转代码、图表转代码等数据，Qwen3-VL学会了连接视觉感知与可执行逻辑，成为一个强大的多模态编程助手。

-   **视频理解**：通过对海量视频源进行平衡采样和长度自适应采样，模型在处理长视频时的信息损失被降到最低，保证了对视频内容的连贯理解。

### 从预训练到后训练的精细打磨

拥有了先进的架构和优质的数据后，精细的训练流程是成功的最后一块拼图。Qwen3-VL的训练分为预训练和后训练两个主要阶段。

预训练分为四步，逐步将模型的上下文窗口从8K扩展到32K，最终达到惊人的256K。在最后的超长上下文适应阶段，模型在一个专门构建的100B Token数据集上进行训练，重点强化长视频和长文档的理解能力。

后训练则更为复杂，包括三个核心环节：

-   **监督微调（SFT）**：使用高质量的指令数据，扩展模型在空间推理、视频时空定位等新能力上的表现。

-   **强模型到弱模型的蒸馏**：利用更强教师模型的知识来提升轻量级模型的性能。

-   **强化学习（RL）**：通过引入基于规则或代码执行器的确定性反馈，以及基于多任务的通用奖励模型，对模型的推理能力和泛化能力进行最终对齐和优化。

值得一提的是，该研究还推出了“思考”（Thinking）版本模型。通过在训练中引入**长链式思维**（**Long Chain-of-Thought, CoT**）数据，这些模型在处理复杂的推理任务时表现出明显更强的性能。

### 性能表现：多项基准测试登顶

最终的实验结果证明了Qwen3-VL的卓越性能。无论是20亿参数的小模型，还是2350亿参数的旗舰模型，都在各大基准测试中展现出强大的竞争力。

在**多模态推理**（**Multimodal Reasoning**）方面，Qwen3-VL-235B在MathVista、MathVision、MMMU等多个高难度STEM基准测试中取得了SOTA或极具竞争力的结果。

即使是小尺寸模型也同样出色。例如，Qwen3-VL-8B在MMBench、MMStar等通用视觉问答基准上全面领先，甚至2B模型也展现出强大的推理能力。

### 结语

Qwen3-VL通过架构创新、数据革新和精细化的训练流程，成功打造了一个性能卓越、功能全面的多模态基础模型。它不仅在传统的图文理解任务上表现出色，更在长上下文处理、视频理解和复杂推理等前沿领域树立了新的标杆。

未来，我们有理由相信，Qwen3-VL将成为驱动图像辅助推理、Agent决策和多模态代码智能等真实世界应用的核心引擎。